{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Materiály vznikají průběžně a jsou bez záruky - prosím o report chyb :-)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "from sympy import *\n",
    "from scipy.stats import norm, uniform, expon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Teorie odhadu](https://en.wikipedia.org/wiki/Estimation_theory) - bodové odhady\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Definice ([Nestrannost odhadu](https://en.wikipedia.org/wiki/Bias_of_an_estimator))**\n",
    ">\n",
    ">Odhad $\\hat \\theta_n$ parametru $\\theta$ se nazývá **nestranný** (**nevychýlený**), jestliže\n",
    ">    \n",
    "> $$\\mathrm{E} \\hat\\theta_n(X_1,\\dotsc,X_n) = \\theta,\\qquad \\text{pro všechna}\\ \\theta\\in \\Theta.$$\n",
    "\n",
    "Nestranný odhad není zatížen systematickou chybou, tj. ve střední hodnotě je roven skutečné hodnotě parametru.\n",
    "\n",
    "> **Definice ([Konzistence odhadu](https://en.wikipedia.org/wiki/Consistent_estimator))**\n",
    ">\n",
    "> Odhad $\\hat \\theta_n$ parametru $\\theta$ se nazývá **konzistentní**, jestliže pro každé $\\epsilon > 0$ a $\\theta \\in \\Theta$ platí\n",
    ">\n",
    "> $$\\lim_{n\\to +\\infty}\\mathrm{P}\\big(|\\hat\\theta_n(X_1,\\dotsc,X_n) - \\theta| \\geq \\epsilon\\big) = 0.$$\n",
    "\n",
    "Konzistence tedy znamená, že s rostoucím rozsahem výběru bude odhad blíže skutečné hodnotě parametru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ilustrace z praxe\n",
    "\n",
    "**Uvažujme, že stojíme před fakultou a zjišťujeme svou geografickou polohu pomocí GPS:**\n",
    "\n",
    "![fit](img/fit-budova.jpg)\n",
    "(zdroj: www.fit.cvut.cz)\n",
    "\n",
    "Jinými slovy, máme **model** pro naši polohu (např. 2D gaussovku), jehož **parametrem (střední hodnotou) je naše skutečná poloha**. Tento parametr **neznáme**, ale budeme jej **odhadovat**.\n",
    "\n",
    "Pokud budeme stát na místě, bude každé naše měření (realizace/pozorování náhodné veličiny) z GPS zatíženo **chybami** v důsledku interferencí, šumů v atmosféře, odrazů atd. Pokud získáme nové měření každých např. 100ms, tj. 10 měření za sekundu, a tato měření budeme průměrovat, můžeme očekávat, že odhad naší polohy se bude vylepšovat. Pokud bude odhad **konzistentní**, potom čím déle budeme měření sbírat (hle, náhodný výběr), tím bude náš odhad přesnější a limitně bude nekonečně přesný. Do 1.5. 2000 byla přesnost GPS zatížena takzvanou SA ([Selective Availability](https://en.wikipedia.org/wiki/Error_analysis_for_the_Global_Positioning_System#Selective_availability)) chybou, která způsobovala inkonzistenci a vychýlenost odhadu.\n",
    "\n",
    "Pokud by byl odhad **vychýlený**, potom bychom systematicky dostávali polohu někde vedle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V angličtině:**\n",
    "\n",
    "- rozlišujeme *odhad* \"estimate\" (číslo) a \"estimator\" (matematická formule)\n",
    "- ne|vychýlený odhad - un|biased estimate, un|biased estimator, un|biasedness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nejběžnější bodové odhady\n",
    "\n",
    "- Výběrový průměr\n",
    "\n",
    "$$\n",
    "\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i,\n",
    "$$\n",
    "\n",
    "- výběrový rozptyl nestranný (po [Besselově korekci](https://en.wikipedia.org/wiki/Bessel%27s_correction))\n",
    "\n",
    "$$\n",
    "s_n^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X}_n)^2,\n",
    "$$\n",
    "\n",
    "- výběrová směrodatná odchylka\n",
    "\n",
    "$$\n",
    "s_n = \\sqrt{s_n^2},\n",
    "$$\n",
    "\n",
    "- $k$. obecný výběrový moment\n",
    "\n",
    "$$\n",
    "\\bar{X}_n^k = m_k = \\frac{1}{n} \\sum_{i=1}^n X_i^k,\n",
    "$$\n",
    "\n",
    "- dále pak výběrová kovariance, výběrový korelační koeficient atd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentová metoda [(wiki)](https://en.wikipedia.org/wiki/Method_of_moments_(statistics))\n",
    "\n",
    "Pravděpodobným autorem momentové metody je Čebyšev. Pomocí této metody získáme odhady, jež jsou zpravidla konzistentní (podle limitních vět), ale často vychýlené. Shrňme si ji do několika málo bodů (pozn.: na přednášce byla vyložena s trochu jiným značením. Zde je to ekvivalentní, ale **učte se z přednáškových materiálů**.):\n",
    "\n",
    "- **Cíl:** odhadnout $k$ parametrů $\\theta_1, \\ldots, \\theta_k$ nějaké distribuce $F_X(x) = F_X(x; \\theta_1,\\ldots, \\theta_k)$.\n",
    "- Distribuce má **teoretické momenty** dané **nějakými** funkcemi parametrů $\\theta_1,\\ldots,\\theta_k$, označme tyto funkce $g_1, g_2$ atd. Pro $k$ neznámých jich potřebujeme $k$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{E}X &= g_1(\\theta_1, \\ldots, \\theta_k),\\\\\n",
    "\\mathrm{E}X^2 &= g_2(\\theta_1, \\ldots, \\theta_k),\\\\\n",
    "\\vdots &\\\\\n",
    "\\mathrm{E}X^k &= g_k(\\theta_1, \\ldots, \\theta_k),\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Současně můžeme počítat **výběrové momenty** nezávislé na distribuci:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m_1 &= \\frac{1}{n} \\sum_{i=1}^n x_i = \\bar{X}_n\\\\\n",
    "m_2 &= \\frac{1}{n} \\sum_{i=1}^n x_i^2 = \\bar{X}_n^2\\\\\n",
    "\\vdots & \\\\\n",
    "m_k &= \\frac{1}{n} \\sum_{i=1}^n x_i^k = \\bar{X}_n^k\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- MoM hledá odhady $\\theta_1,\\ldots,\\theta_k$ označené $\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_k$ položením **rovnosti** mezi teoretickými a výběrovými momenty:\n",
    "$$\n",
    "\\begin{align}\n",
    "m_1 &= g_1(\\hat{\\theta}_1, \\ldots, \\hat{\\theta}_k)\\\\\n",
    "m_2 &= g_2(\\hat{\\theta}_1, \\ldots, \\hat{\\theta}_k)\\\\\n",
    "\\vdots & \\\\\n",
    "m_k &= g_k(\\hat{\\theta}_1, \\ldots, \\hat{\\theta}_k)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Tedy např. pro distribuci s jedním parametrem $\\theta$ máme\n",
    "\n",
    "$$\n",
    "m_1 = g_1(\\hat\\theta) \\Rightarrow \\hat{\\theta} = g_1^{-1}(m_1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příklad 9.1\n",
    "\n",
    "**Předpokládejme, že délka transakce databázového serveru je náhodná veličina s exponenciálním rozdělením s parametrem $\\lambda$. Délky transakcí jsou nezávislé.**\n",
    "\n",
    "**a) Odvoďte odhad $\\lambda$ momentovou metodou.**\n",
    "\n",
    "Sepíšeme, co potřebujeme:\n",
    "\n",
    "- Exponenciální distribuce má jediný parametr $\\lambda\\geq 0$ - budeme potřebovat jen jednu rovnici pro první moment.\n",
    "- $\\mathrm{E} X = \\frac{1}{\\lambda} = g_1(\\lambda)$\n",
    "- $m_1 = \\bar{X}_n$\n",
    "\n",
    "A řešíme:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m_1 &= g_1(\\hat{\\lambda}) \\\\\n",
    "\\bar{X}_n &= \\frac{1}{\\hat{\\lambda}} \\\\\n",
    "\\hat{\\lambda} &= \\frac{1}{\\bar{X}_n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Odhadem $\\lambda$ je tedy převrácená hodnota aritmetického průměru.\n",
    "\n",
    "**b) Z logu jsme zjistili, že délky posledních 5 transakcí byly: $5,\\!4$; $15,\\!6$; $9,\\!3$; $0,\\!5$ a $2,\\!6$ ms. Určete číselnou hodnotu předchozího odhadu.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odhad lambda je  0.14970059880239522\n"
     ]
    }
   ],
   "source": [
    "X = np.array([5.4, 15.6, 9.3, 0.5, 2.6])\n",
    "print('Odhad lambda je ', 1/X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximálně věrohodný odhad ([MLE, Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation))\n",
    "\n",
    "MLE je v současné době připisováno Britu [R.A. Fisherovi](https://en.wikipedia.org/wiki/Ronald_Fisher), který se postaral o rozšíření a popularizaci metody. Před ním už ale byla známa např. Gaussovi či Laplaceovi. \n",
    "\n",
    "Shrňme si ji rovněž do několika málo bodů:\n",
    "\n",
    "- **Cíl:** hledáme odhad $\\hat{\\theta}$ parametru $\\theta$ nějakého **statistického modelu**, tj. **distribuce**.\n",
    "- Distribuce má **hustotu** $f_X(x) \\equiv f_X(x; \\theta)$.\n",
    "- Budeme se ale zabývat [**věrohodností (likelihoodem)**](https://en.wikipedia.org/wiki/Likelihood_function) $\\mathcal{L}(\\theta) \\equiv \\mathcal{L}(\\theta; X) \"\\equiv f_X(x; \\theta)\"$, kde ale **$X$ jsou fixována** (vzpomeňte, v hustotě jsme fixovali $\\theta$), jinak je to \"stejná funkce\".\n",
    "- zatímco hustota je tedy funkce $x$, likelihood je funkce $\\theta$. \n",
    "- Pro $n$ pozorování máme **fixovaná data, neznámý parametr a jeho věrohodnost**\n",
    "\n",
    "$$\n",
    "f_X(X_1 = x_1; \\theta) \\cdot f_X(X_2=x_2; \\theta) \\cdots f_X(X_n=x_n;\\theta) = f(x_1, x_2,\\ldots, x_n; \\theta) = f(x; \\theta)\n",
    "= \\mathcal{L}(\\theta; x)\\\n",
    "$$\n",
    "\n",
    "- **MLE maximalizuje věrohodnost** přes celou množinu hodnot $\\theta$ označenou $\\Theta$:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\in \\left\\{ \\arg\\max_{\\theta\\in\\Theta} \\mathcal{L}(\\theta; x) \\right\\}.\n",
    "$$\n",
    "\n",
    "- V praxi se používá logaritmus věrohodnosti, tzv. loglikelihood\n",
    "\n",
    "$$\n",
    "\\mathcal{l}(\\theta) \\equiv \\mathcal{l}(\\theta; x) = \\ln \\mathcal{L}(\\theta; x).\n",
    "$$\n",
    "\n",
    "Dokážete uhodnout proč? \n",
    "\n",
    "- Nápověda 1: Mnoho hustot má v sobě exponenciální funkci.\n",
    "- Nápověda 2: Jak hledáme maximum funkce?\n",
    "- Nápověda 3: Likelihoody resp. hustoty jsou zpravidla dost malá čísla, menší než 1. Co když jich spoustu vynásobíme?\n",
    "\n",
    "Řešení je níže :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logaritmus nás často zbaví exponenciální funkce, viz příklad níže. Lépe se pak počítá. Logaritmus součinu hustot (likelihoodů) je součet logaritmů těchto funkcí. Opět se lépe počítá a NAVÍC je to numericky mnohem stabilnější, neboť součin má tendence brzy skončit kvůli konečné přesnosti počítače na nule'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "codecs.encode('Ybtnevgzhf aáf čnfgb monií rkcbarapváyaí shaxpr, ivm cříxynq aížr. Yécr fr cnx cbčígá. '\n",
    "              +'Ybtnevgzhf fbhčvah uhfgbg (yvxryvubbqů) wr fbhčrg ybtnevgzů gěpugb shaxpí. Bcěg fr yécr '\n",
    "              +'cbčígá n ANIÍP wr gb ahzrevpxl zaburz fgnovyaěwší, arobť fbhčva zá graqrapr oeml fxbačvg '\n",
    "              +'xiůyv xbarčaé cřrfabfgv cbčígnčr an ahyr', 'rot_13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda maximální věrohodnosti graficky\n",
    "\n",
    "Uvažujme, že máme náhodný výběr o rozsahu $n=5$ s realizacemi $X_1=5.1, X_2=4.8, X_3 = 4.6, X_4=5, X_5=5.5$. Ten vygeneroval jednoduchoučký proces ve tvaru\n",
    "\n",
    "$$\n",
    "X_i \\sim \\mathcal{N}(a, 1),\n",
    "$$\n",
    "\n",
    "Máme odhadovat střední hodnotu $a$ metodou maximální věrohodnosti, ostatní parametry jsou známé. \n",
    "Připomeňme, že věrohodnost (likelihood) počítáme jako součin\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(a; x_1,\\ldots,x_5) = \\mathcal{L}(a;x) = f(x_1;a) \\cdot f(x_2;a) \\cdots f(x_5;a),\n",
    "$$\n",
    "\n",
    "Kdybychom postupovali metodou pokus-omyl, mohli bychom vidět např. toto:\n",
    "\n",
    "![ml-graficky](img/ml-graficky.png)\n",
    "\n",
    "MLE i MoM odhadem střední hodnoty je aritmetický průměr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Průměr Y: 4.9800\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([5.1, 4.8, 4.6, 5, 5.4])\n",
    "print(f\"Průměr Y: {Y.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Někdy to ale nejde tak snadno, v mnohých složitějších modelech se počítá odhad maximalizací věrohodnosti (likelihoodu) numericky. Zkusíme to také, ve `scipy` je ale jen funkce `minimize()`, takže musíme minimalizovat věrohodnosti se záporným znaménkem. A pro numerickou stabilitu v obecných případech lépe než věrohodnosti to budou jejich logaritmy (loglikelihoody):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 4.778692666023371\n",
      " hess_inv: array([[0.2]])\n",
      "      jac: array([-2.384e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([4.98])\n"
     ]
    }
   ],
   "source": [
    "def negative_loglikelihood(a):\n",
    "    loglikelihoods = norm.logpdf(Y, loc=a, scale=1)\n",
    "    return -np.sum(loglikelihoods)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "res = minimize(negative_loglikelihood, x0=0, options={'disp': False})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příklad 9.3\n",
    "\n",
    "**Předpokládejme, že délka transakce databázového serveru je náhodná veličina s exponenciálním rozdělením s parametrem $\\lambda$. Délky transakcí jsou nezávislé.**\n",
    "\n",
    "**a) Odvoďte odhad $\\lambda$ metodou maximální věrohodnosti.**\n",
    "\n",
    "Sepíšeme, co potřebujeme:\n",
    "\n",
    "- Exponenciální distribuce má jediný parametr $\\lambda\\geq 0$ - budeme maximalizovat jen přes jeden parametr.\n",
    "- $f(x) = \\lambda e^{-\\lambda x}$\n",
    "\n",
    "Tedy\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\lambda; x) = \\mathcal{L}(\\lambda; x_1, \\ldots, x_n) = \\prod_{i=1}^n f(x_i) = \\prod_{i=1}^n \\lambda e^{-\\lambda x_i}\n",
    "$$\n",
    "\n",
    "Můžeme buď hledat maximum derivací likelihoodu, nebo si zlogaritmujeme\n",
    "\n",
    "$$\n",
    "\\mathcal{l}(\\lambda; x) = \\ln \\mathcal{L}(\\lambda; x) = \\sum_{i=1}^n \\ln \\lambda e^{-\\lambda x_i} = n \\ln \\lambda - \\lambda\\sum_{i=1}^n x_i.\n",
    "$$\n",
    "\n",
    "Maximum dostaneme snadno derivací a položením rovnosti nule,\n",
    "\n",
    "$$\n",
    "\\frac{d\\mathcal{l}(\\lambda;x)}{d\\lambda} = \\frac{n}{\\hat\\lambda} - \\sum_{i=1}^n x_i = 0\n",
    "\\qquad \\Longrightarrow \\qquad \\hat\\lambda = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\bar{X}_n}.\n",
    "$$\n",
    "\n",
    "\n",
    "Odhadem $\\lambda$ je tedy opět převrácená hodnota aritmetického průměru.\n",
    "\n",
    "**b) Z logu jsme zjistili, že délky posledních 5 transakcí byly: $5,\\!4$; $15,\\!6$; $9,\\!3$; $0,\\!5$ a $2,\\!6$ ms. Určete číselnou hodnotu předchozího odhadu.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odhad lambda je 0.1497.\n"
     ]
    }
   ],
   "source": [
    "X = np.array([5.4, 15.6, 9.3, 0.5, 2.6])\n",
    "print(f\"Odhad lambda je {1/X.mean():.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V `scipy.stats` máme i exponenciální distribuci `expon` a ta má - stejně jako ostatní distribuce v scipy - metodu `fit()` využívající MLE. Ovšem pozor na parametrizaci, je třeba **velmi** pečlivě studovat [manuál](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE odhad lambda ve scipy je 0.1497.\n"
     ]
    }
   ],
   "source": [
    "loc, scale = expon.fit(X, floc=0)\n",
    "print(f'MLE odhad lambda ve scipy je {1/scale:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Příklady ze slajdů"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Příklad 9.2\n",
    "\n",
    "**Nalezněte odhad parametrů $a, b\\in\\mathbb{R}$ spojitého rovnoměrného rozdělení $\\mathcal{U}(a,b)$ momentovou metodou.**\n",
    "\n",
    "Máme dva parametry, budeme potřebovat dvě rovnice, tedy první a druhé momenty. Víme, nebo si spočteme, že:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{E}X &= \\frac{1}{2}(a+b) \\\\\n",
    "\\mathrm{E}X^2 &= \\frac{1}{3}(a^2 + ab + b^2).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "První dva momenty výběrové jsou stále stejné, tj. $m_1 = \\bar{X}_n, m_2 = \\bar{X}_n^2$.\n",
    "\n",
    "Tedy máme soustavu\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bar{X}_n &= \\frac{1}{2}(\\hat a+\\hat b) \\\\\n",
    "\\bar{X}_n^2 &= \\frac{1}{3}(\\hat a^2 + \\hat a\\hat b + \\hat b^2).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "jejíž řešením je\n",
    "\n",
    "$$\n",
    "\\hat{a} = \\bar{X}_n - \\sqrt{3[\\bar{X}_n^2 - (\\bar{X}_n)^2]} = m_1 - \\sqrt{3(m_2 - m_1^2)} \\\\\n",
    "\\hat{b} = \\bar{X}_n + \\sqrt{3[\\bar{X}_n^2 - (\\bar{X}_n)^2]} = m_1 + \\sqrt{3(m_2 - m_1^2)}.\n",
    "$$\n",
    "\n",
    "(Pro jistotu jsou doplněny $m_1, m_2$, v těch průměrech je snadné se ztratit).\n",
    "\n",
    "Tento odhad není konzistentní, může dávat $\\hat{a}<a, \\hat{b}>b$. Zkuste několikrát pustit následující kód, odhadující $[a,b] = [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odhady a=-0.08, b=1.04\n"
     ]
    }
   ],
   "source": [
    "x = uniform.rvs(size=10)\n",
    "m1 = x.mean()\n",
    "m2 = np.mean(x**2)\n",
    "hat_a = m1 - np.sqrt(3 * (m2 - m1**2))\n",
    "hat_b = m1 + np.sqrt(3 * (m2 - m1**2))\n",
    "print('odhady a={0:.2f}, b={1:.2f}'.format(hat_a, hat_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Příklad 9.4\n",
    "\n",
    "**Generátor náhodných čísel generuje hodnoty z rovnoměrného rozdělení na intervalu $[0,b]$, kde $b$ je neznámá horní mez.**\n",
    "\n",
    "Už teď víme, že $\\mathcal{U}(0, b)$ má na intervalu $[0, b]$ hustotu $f(x) = \\frac{1}{b}$ a jinde 0. Parametr máme pouze jeden $\\theta \\equiv b$.\n",
    "\n",
    "**a) Nalezněte odhad $b$ momentovou metodou.**\n",
    "\n",
    "Budeme potřebovat jen jednu rovnici - pro první moment, sepišme si tedy teoretické a výběrové momenty:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{E}X &= \\frac{b}{2} \\\\\n",
    "m_1 &= \\bar{X_n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Z toho nám plyne, že\n",
    "\n",
    "$$\n",
    "m_1 = \\bar{X_n} = \\frac{\\hat{b}}{2} \\qquad \\Longrightarrow \\qquad \\hat{b} = 2\\bar{X_n}.\n",
    "$$\n",
    "\n",
    "**b) Nalezněte odhad $b$ metodou maximální věrohodnosti.**\n",
    "\n",
    "Napišme si likelihood,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(b; x) = \\prod_{i=1}^n \\frac{1}{b} = b^{-n}.\n",
    "$$\n",
    "\n",
    "Log-likelihood je\n",
    "\n",
    "$$\n",
    "\\mathcal{l}(b; x) = \\ln \\mathcal{L}(b; x) = -n \\log b,\n",
    "$$\n",
    "\n",
    "a jeho derivace pro hledání maxima\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{l}(b; x)}{db} = -\\frac{n}{b}.\n",
    "$$\n",
    "\n",
    "Nebudeme to klást rovné nule, ale musíme se podívat na omezení:\n",
    "\n",
    "1. $b>0$\n",
    "2. Výsledek derivace je **klesající**. Maximum tedy bude dosaženo v $\\max \\{x_1, \\ldots, x_n\\}$. Tedy\n",
    "\n",
    "$$\n",
    "\\hat{b} = \\max \\{x_1, \\ldots, x_n\\}.\n",
    "$$\n",
    "\n",
    "**c) Ověřte nestrannost předchozích odhadů.**\n",
    "\n",
    "MoM odhad je nestranný, neboť\n",
    "\n",
    "$$\n",
    "\\mathrm{E}\\hat{b} = 2\\mathrm{E}\\bar{X_n} = 2 \\frac{1}{n} \\sum \\mathrm{E}X_i = b\n",
    "$$\n",
    "\n",
    "MLE odhad není nestranný, neboť\n",
    "\n",
    "$$\n",
    "\\mathrm{E}\\hat{b} = \\mathrm{E}\\left[\\max\\{x_1, \\ldots, x_n\\} \\right] = \\max\\{\\mathrm{E}X_1, \\ldots, \\mathrm{E}X_n\\} < b,\n",
    "$$\n",
    "\n",
    "protože pravděpodobnost $P(X=b)=0$ vzhledem ke spojitému rozdělení.\n",
    "\n",
    "Uspořádejme si nyní $x_i$ podle velikosti a přeznačme je tak, aby $X_1 \\leq X_2 \\leq \\ldots \\leq X_n$. Jelikož jde o rovnoměrné rozdělení, jsou všechny intervaly mezi dvěma po sobě následujícími body stejně rozdělené a\n",
    "\n",
    "$$\n",
    "\\mathrm{E}[X_1 - 0] = \\mathrm{E}[X_2 - X_1] = \\ldots = \\mathrm{E}[X_n - X_{n-1}] = \\mathrm{E}[b - X_n] = \\frac{b}{n+1}.\n",
    "$$\n",
    "\n",
    "Tedy \n",
    "\n",
    "$$\n",
    "\\mathrm{E}[b - \\max\\{X_1, \\ldots, X_n\\}] = \\frac{b}{n+1}\\qquad \\Longrightarrow \\qquad b - \\mathrm{E}\\hat{b} = \\frac{b}{n+1}\n",
    "$$\n",
    "\n",
    "a korigovaný nestranný odhad tedy je\n",
    "\n",
    "$$\n",
    "\\hat{b}' = \\frac{n+1}{n} \\hat{b}. \n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
